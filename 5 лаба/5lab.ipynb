{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка и изучение датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "# Загрузка данных\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Преобразование в DataFrame для удобства работы\n",
    "df = pd.DataFrame(data=X, columns=data.feature_names)\n",
    "df['target'] = y\n",
    "\n",
    "# Удаление или заполнение пропусков\n",
    "imp = SimpleImputer(strategy=\"mean\")\n",
    "X_imputed = imp.fit_transform(X)\n",
    "\n",
    "# Разделение на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imputed, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Масштабирование\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius                0\n",
      "mean texture               0\n",
      "mean perimeter             0\n",
      "mean area                  0\n",
      "mean smoothness            0\n",
      "mean compactness           0\n",
      "mean concavity             0\n",
      "mean concave points        0\n",
      "mean symmetry              0\n",
      "mean fractal dimension     0\n",
      "radius error               0\n",
      "texture error              0\n",
      "perimeter error            0\n",
      "area error                 0\n",
      "smoothness error           0\n",
      "compactness error          0\n",
      "concavity error            0\n",
      "concave points error       0\n",
      "symmetry error             0\n",
      "fractal dimension error    0\n",
      "worst radius               0\n",
      "worst texture              0\n",
      "worst perimeter            0\n",
      "worst area                 0\n",
      "worst smoothness           0\n",
      "worst compactness          0\n",
      "worst concavity            0\n",
      "worst concave points       0\n",
      "worst symmetry             0\n",
      "worst fractal dimension    0\n",
      "target                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Проверка на наличие пропусков\n",
    "missing_data = df.isnull().sum()\n",
    "print(missing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Проверка на наличие категориальных признаков\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagging_params = {\n",
    "    'n_estimators':[5, 10, 50, 100]\n",
    "}\n",
    "\n",
    "tree_params = {\n",
    "    'n_estimators':[50, 100, 150, 200]\n",
    "}\n",
    "\n",
    "adaboost_params = {\n",
    "    'n_estimators':[30, 50, 100, 150]\n",
    "}\n",
    "\n",
    "gradient_params = {\n",
    "    'n_estimators':[50, 100, 150, 200]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# Бэггинг\n",
    "\n",
    "RANDOM_STATE=123\n",
    "\n",
    "grid_search = GridSearchCV(estimator=BaggingRegressor(random_state=RANDOM_STATE), param_grid=bagging_params, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "bagging = grid_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=RandomForestRegressor(random_state=RANDOM_STATE), param_grid=tree_params, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "random_forest = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=AdaBoostRegressor(estimator=DecisionTreeRegressor(), random_state=RANDOM_STATE), param_grid=adaboost_params, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "adaboost = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=AdaBoostRegressor(random_state=RANDOM_STATE), param_grid=adaboost_params, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "adaboost_limited_tree_depth = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучшие параметры: {'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=GradientBoostingRegressor(random_state=RANDOM_STATE), param_grid=gradient_params, cv=3)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {grid_search.best_params_}\")\n",
    "gradient_boosting = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_bagging = bagging.predict(X_test_scaled)\n",
    "y_pred_rf = random_forest.predict(X_test_scaled)\n",
    "y_pred_adaboost = adaboost.predict(X_test_scaled)\n",
    "y_pred_adaboost_limited = adaboost_limited_tree_depth.predict(X_test_scaled)\n",
    "y_pred_gb = gradient_boosting.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging: 0.0751\n",
      "Random Forest: 0.0760\n",
      "AdaBoost: 0.0409\n",
      "AdaBoost (tree depth = 3): 0.0820\n",
      "Gradient Boosting: 0.0789\n"
     ]
    }
   ],
   "source": [
    "# MAE\n",
    "print(f\"Bagging: {mean_absolute_error(y_test, y_pred_bagging):.4f}\")\n",
    "print(f\"Random Forest: {mean_absolute_error(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"AdaBoost: {mean_absolute_error(y_test, y_pred_adaboost):.4f}\")\n",
    "print(f\"AdaBoost (tree depth = 3): {mean_absolute_error(y_test, y_pred_adaboost_limited):.4f}\")\n",
    "print(f\"Gradient Boosting: {mean_absolute_error(y_test, y_pred_gb):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging: 0.8498\n",
      "Random Forest: 0.8592\n",
      "AdaBoost: 0.8241\n",
      "AdaBoost (tree depth = 3): 0.8946\n",
      "Gradient Boosting: 0.8678\n"
     ]
    }
   ],
   "source": [
    "# R^2\n",
    "print(f\"Bagging: {r2_score(y_test, y_pred_bagging):.4f}\")\n",
    "print(f\"Random Forest: {r2_score(y_test, y_pred_rf):.4f}\")\n",
    "print(f\"AdaBoost: {r2_score(y_test, y_pred_adaboost):.4f}\")\n",
    "print(f\"AdaBoost (tree depth = 3): {r2_score(y_test, y_pred_adaboost_limited):.4f}\")\n",
    "print(f\"Gradient Boosting: {r2_score(y_test, y_pred_gb):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод\n",
    "\n",
    "На основе анализа метрик MAE и R², AdaBoost является лучшей моделью для данной задачи, так как она показала наименьшую среднюю абсолютную ошибку и наибольшее значение коэффициента детерминации.\n",
    "\n",
    "Однако по умолчанию в AdaBoost используется DecisionTreeRegressor с ограничением глубины дерева, что сильно ухудшает результаты.\n",
    "\n",
    "Остальные модели показали примерно одинаковый результат."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
